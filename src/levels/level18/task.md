### Дедовский Ликбез

Любой сайт — это клубок ссылок. Они ведут на другие страницы, на картинки, на внешние ресурсы. Умение быстро выдрать из этого клубка нужные тебе нитки — бесценно.

Комбинация `cat` (или `curl`) и `grep` — твой главный инструмент для этого. С помощью `grep` и регулярных выражений можно творить настоящую магию: доставать из тонны HTML-говна только то, что тебе нужно.

### Твоя Задача

В файле `page.html` лежит кусок HTML-кода с несколькими ссылками. Мне нужны только те, которые ведут на домен `target.com`.

Построй конвейер, который прочитает файл `page.html`, найдёт все ссылки (`href="..."`) и извлечёт из них только адреса, содержащие `target.com`. Результат сохрани в файл `links.txt`.

### Подсказка от Деда

Регулярные выражения — это мощь. `grep -o 'https://target.com/[^"]*'` — хороший старт. Флаг `-o` заставляет `grep` показывать не всю строку, а только совпавшую часть. Разбирайся.
